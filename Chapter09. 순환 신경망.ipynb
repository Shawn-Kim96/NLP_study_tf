{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec582416",
   "metadata": {},
   "source": [
    "# SimpleRNN, LSTM in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48933a1",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d48fab16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T06:10:54.803148Z",
     "start_time": "2021-12-04T06:10:54.800718Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1952324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T06:08:46.699257Z",
     "start_time": "2021-12-04T06:08:46.695565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
    "train_X = np.array(train_X, dtype=np.float32)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f394ab6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T06:12:03.264524Z",
     "start_time": "2021-12-04T06:12:03.259547Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size=5, hidden_size=3, batch_first=True)\n",
    "hidden_state = rnn(torch.Tensor(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7132b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T06:12:25.058876Z",
     "start_time": "2021-12-04T06:12:25.056332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3])\n",
      "torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "for x in hidden_state:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feebd030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T06:13:04.091019Z",
     "start_time": "2021-12-04T06:13:04.086572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.6037,  0.3148,  0.9215],\n",
       "          [-0.2451,  0.4842,  0.1278],\n",
       "          [-0.4799, -0.7831,  0.0037],\n",
       "          [ 0.1668, -0.8375,  0.9610]]], grad_fn=<TransposeBackward1>),\n",
       " tensor([[[ 0.1668, -0.8375,  0.9610]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33186574",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df3e118e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T06:15:21.990221Z",
     "start_time": "2021-12-04T06:15:21.984454Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=5, hidden_size=3, batch_first=True, bidirectional=True)\n",
    "output, (h_n, c_n) = lstm(torch.Tensor(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc78ee90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-04T06:15:22.458111Z",
     "start_time": "2021-12-04T06:15:22.452708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4927, -0.5936, -0.1566, -0.0501,  0.3646,  0.2888],\n",
      "         [ 0.6602, -0.6393, -0.3721, -0.1072,  0.0677,  0.1797],\n",
      "         [ 0.4946, -0.6110, -0.4594, -0.0567,  0.1437,  0.2343],\n",
      "         [ 0.6278, -0.3790, -0.4976, -0.0691, -0.0278,  0.3694]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.6278, -0.3790, -0.4976]],\n",
      "\n",
      "        [[-0.0501,  0.3646,  0.2888]]], grad_fn=<StackBackward>)\n",
      "tensor([[[ 0.9288, -0.6268, -1.2566]],\n",
      "\n",
      "        [[-1.0342,  0.9499,  0.6844]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "print(h_n)\n",
    "print(c_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcaef14",
   "metadata": {},
   "source": [
    "# RNN을 이용한 텍스트 생성\n",
    "\n",
    "* Tensorflow 로 되어있는 코드를 pytorch로 전환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828768a8",
   "metadata": {},
   "source": [
    "## RNN 모델 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f336e6",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "b08ad311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:06:45.994435Z",
     "start_time": "2021-12-05T06:06:45.991496Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "26355ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:06:46.149237Z",
     "start_time": "2021-12-05T06:06:46.145990Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
    "그의 말이 법이다\\n\n",
    "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "cb94315c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:06:46.299681Z",
     "start_time": "2021-12-05T06:06:46.297148Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "eaba2974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:06:46.449704Z",
     "start_time": "2021-12-05T06:06:46.446232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'말이': 1,\n",
       " '경마장에': 2,\n",
       " '있는': 3,\n",
       " '뛰고': 4,\n",
       " '있다': 5,\n",
       " '그의': 6,\n",
       " '법이다': 7,\n",
       " '가는': 8,\n",
       " '고와야': 9,\n",
       " '오는': 10,\n",
       " '곱다': 11}"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "c3bcc6d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:06:46.607447Z",
     "start_time": "2021-12-05T06:06:46.603927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 개수: 11\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for line in text.split('\\n'):\n",
    "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "print(f'학습에 사용할 샘플의 개수: {len(sequences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "e685a1f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:06:46.766408Z",
     "start_time": "2021-12-05T06:06:46.762419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3],\n",
       " [2, 3, 1],\n",
       " [2, 3, 1, 4],\n",
       " [2, 3, 1, 4, 5],\n",
       " [6, 1],\n",
       " [6, 1, 7],\n",
       " [8, 1],\n",
       " [8, 1, 9],\n",
       " [8, 1, 9, 10],\n",
       " [8, 1, 9, 10, 1],\n",
       " [8, 1, 9, 10, 1, 11]]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "27943512",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:06:47.295887Z",
     "start_time": "2021-12-05T06:06:47.291383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  0,  2,  3,  1],\n",
       "       [ 0,  0,  2,  3,  1,  4],\n",
       "       [ 0,  2,  3,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  6,  1,  7],\n",
       "       [ 0,  0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9],\n",
       "       [ 0,  0,  8,  1,  9, 10],\n",
       "       [ 0,  8,  1,  9, 10,  1],\n",
       "       [ 8,  1,  9, 10,  1, 11]], dtype=int32)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전체 백터의 크기를 맞춰주는 작업 진행\n",
    "max_len = max([len(x) for x in sequences])\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "26e35752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:06:47.906404Z",
     "start_time": "2021-12-05T06:06:47.900159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2]\n",
      " [ 0  0  0  2  3]\n",
      " [ 0  0  2  3  1]\n",
      " [ 0  2  3  1  4]\n",
      " [ 0  0  0  0  6]\n",
      " [ 0  0  0  6  1]\n",
      " [ 0  0  0  0  8]\n",
      " [ 0  0  0  8  1]\n",
      " [ 0  0  8  1  9]\n",
      " [ 0  8  1  9 10]\n",
      " [ 8  1  9 10  1]]\n",
      "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [:-1] 까지는 입력, [-1] 은 라벨링 값이 된다.\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]\n",
    "print(X), print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "c32b7c66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:06:50.518236Z",
     "start_time": "2021-12-05T06:06:50.510474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32),\n",
       " (11, 12))"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labeling 값을 one-hot encoding으로 바꿔주는 작업\n",
    "y = to_categorical(y, num_classes = vocab_size)\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be281422",
   "metadata": {},
   "source": [
    "### 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "aa488eb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:08:25.682950Z",
     "start_time": "2021-12-05T06:08:25.678087Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class text_RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(text_RNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(input_size=embedding_dim, \n",
    "                          hidden_size=hidden_dim, \n",
    "                          batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        output = self.embedding(inp)\n",
    "        _, output = self.rnn(output)\n",
    "        output = self.linear(output)\n",
    "#         output = self.softmax(output) \n",
    "# nn.CrossEntropyLoss에 이미 softmax 함수가 포함된거라서, 따로 해줄 필요는 없다\n",
    "         \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "b24aea30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:08:27.978783Z",
     "start_time": "2021-12-05T06:08:27.974841Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 10\n",
    "hidden_dim = 32\n",
    "lr = 0.01\n",
    "\n",
    "model = text_RNN(vocab_size=vocab_size,\n",
    "                 embedding_dim=embedding_dim,\n",
    "                 hidden_dim=hidden_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "b3fd74ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:08:33.836376Z",
     "start_time": "2021-12-05T06:08:31.022048Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1.00 :: 2.4310765158046377\n",
      "epoch 2.00 :: 1.4229992573911494\n",
      "epoch 3.00 :: 0.8896948004310782\n",
      "epoch 4.00 :: 0.5604410672729666\n",
      "epoch 5.00 :: 0.3601190610365434\n",
      "epoch 6.00 :: 0.23840859735553915\n",
      "epoch 7.00 :: 0.16520188444040038\n",
      "epoch 8.00 :: 0.11592548205093904\n",
      "epoch 9.00 :: 0.08350600945678624\n",
      "epoch 10.00 :: 0.06320844353599982\n",
      "epoch 11.00 :: 0.049969095906073395\n",
      "epoch 12.00 :: 0.04094145853411068\n",
      "epoch 13.00 :: 0.03445787643167106\n",
      "epoch 14.00 :: 0.029586328955536537\n",
      "epoch 15.00 :: 0.02579465245997364\n",
      "epoch 16.00 :: 0.02276211562143131\n",
      "epoch 17.00 :: 0.02028502727096731\n",
      "epoch 18.00 :: 0.018227602693844925\n",
      "epoch 19.00 :: 0.01649498820982196\n",
      "epoch 20.00 :: 0.015018802601844072\n",
      "epoch 21.00 :: 0.0137483260424977\n",
      "epoch 22.00 :: 0.012645317156883802\n",
      "epoch 23.00 :: 0.011680192991413853\n",
      "epoch 24.00 :: 0.010829922362146053\n",
      "epoch 25.00 :: 0.010076216422021389\n",
      "epoch 26.00 :: 0.009404390373013237\n",
      "epoch 27.00 :: 0.008802372708239338\n",
      "epoch 28.00 :: 0.008260534060272303\n",
      "epoch 29.00 :: 0.007770845920524814\n",
      "epoch 30.00 :: 0.007326397854326801\n",
      "epoch 31.00 :: 0.006921696561304006\n",
      "epoch 32.00 :: 0.0065518975130875005\n",
      "epoch 33.00 :: 0.0062128952281041575\n",
      "epoch 34.00 :: 0.005901273403486068\n",
      "epoch 35.00 :: 0.005614146018739451\n",
      "epoch 36.00 :: 0.005348716439171271\n",
      "epoch 37.00 :: 0.005102927013385025\n",
      "epoch 38.00 :: 0.004874736874956976\n",
      "epoch 39.00 :: 0.004662511679767208\n",
      "epoch 40.00 :: 0.004464711231941526\n",
      "epoch 41.00 :: 0.004279911518096924\n",
      "epoch 42.00 :: 0.004107085903259841\n",
      "epoch 43.00 :: 0.003945195602930405\n",
      "epoch 44.00 :: 0.0037931894608349962\n",
      "epoch 45.00 :: 0.0036502958233044906\n",
      "epoch 46.00 :: 0.0035157748498022556\n",
      "epoch 47.00 :: 0.0033890800444747915\n",
      "epoch 48.00 :: 0.0032694159308448434\n",
      "epoch 49.00 :: 0.0031563428294082933\n",
      "epoch 50.00 :: 0.003049302031286061\n",
      "epoch 51.00 :: 0.0029479607368226757\n",
      "epoch 52.00 :: 0.002851802876896479\n",
      "epoch 53.00 :: 0.0027605815875259314\n",
      "epoch 54.00 :: 0.00267389878122644\n",
      "epoch 55.00 :: 0.0025913884270597587\n",
      "epoch 56.00 :: 0.002512835696424273\n",
      "epoch 57.00 :: 0.0024379931432618337\n",
      "epoch 58.00 :: 0.002366580767557025\n",
      "epoch 59.00 :: 0.0022983940593390303\n",
      "epoch 60.00 :: 0.0022332933625545015\n",
      "epoch 61.00 :: 0.002171009016985243\n",
      "epoch 62.00 :: 0.0021114336453716864\n",
      "epoch 63.00 :: 0.002054340671747923\n",
      "epoch 64.00 :: 0.0019997523314404216\n",
      "epoch 65.00 :: 0.0019472472856498578\n",
      "epoch 66.00 :: 0.0018969232809137213\n",
      "epoch 67.00 :: 0.0018486293953504753\n",
      "epoch 68.00 :: 0.0018022362068718808\n",
      "epoch 69.00 :: 0.0017576032815585759\n",
      "epoch 70.00 :: 0.0017146877415308898\n",
      "epoch 71.00 :: 0.0016733708114109256\n",
      "epoch 72.00 :: 0.0016335770911113782\n",
      "epoch 73.00 :: 0.0015952958704226396\n",
      "epoch 74.00 :: 0.0015583111036738212\n",
      "epoch 75.00 :: 0.0015226228702390058\n",
      "epoch 76.00 :: 0.0014882422136989508\n",
      "epoch 77.00 :: 0.0014550502845932815\n",
      "epoch 78.00 :: 0.0014229389489628375\n",
      "epoch 79.00 :: 0.0013919733305969698\n",
      "epoch 80.00 :: 0.001362002073702487\n",
      "epoch 81.00 :: 0.001332992735445838\n",
      "epoch 82.00 :: 0.0013050104713660073\n",
      "epoch 83.00 :: 0.0012777955588799987\n",
      "epoch 84.00 :: 0.0012515537197362971\n",
      "epoch 85.00 :: 0.0012261227503503587\n",
      "epoch 86.00 :: 0.0012014485493471677\n",
      "epoch 87.00 :: 0.0011774337723512542\n",
      "epoch 88.00 :: 0.0011543166844851592\n",
      "epoch 89.00 :: 0.0011317292492921379\n",
      "epoch 90.00 :: 0.0011098988841033795\n",
      "epoch 91.00 :: 0.0010886957435022023\n",
      "epoch 92.00 :: 0.001068087347613817\n",
      "epoch 93.00 :: 0.0010481279089369557\n",
      "epoch 94.00 :: 0.0010286767977628517\n",
      "epoch 95.00 :: 0.001009755598550493\n",
      "epoch 96.00 :: 0.0009913319795900447\n",
      "epoch 97.00 :: 0.0009735141224651175\n",
      "epoch 98.00 :: 0.0009561505734878169\n",
      "epoch 99.00 :: 0.0009392088713039728\n",
      "epoch 100.00 :: 0.0009227539994753897\n",
      "epoch 101.00 :: 0.0009066885368983177\n",
      "epoch 102.00 :: 0.0008910341474058276\n",
      "epoch 103.00 :: 0.0008758450011638078\n",
      "epoch 104.00 :: 0.0008609695809850978\n",
      "epoch 105.00 :: 0.0008465486250563779\n",
      "epoch 106.00 :: 0.0008324630246286026\n",
      "epoch 107.00 :: 0.0008187128590758551\n",
      "epoch 108.00 :: 0.0008052872858983887\n",
      "epoch 109.00 :: 0.0007922296380539509\n",
      "epoch 110.00 :: 0.0007794749505013566\n",
      "epoch 111.00 :: 0.0007670015885113654\n",
      "epoch 112.00 :: 0.0007548420610625974\n",
      "epoch 113.00 :: 0.0007429747149051929\n",
      "epoch 114.00 :: 0.0007313887366432358\n",
      "epoch 115.00 :: 0.0007200841447973454\n",
      "epoch 116.00 :: 0.0007089959584515203\n",
      "epoch 117.00 :: 0.0006981566839385778\n",
      "epoch 118.00 :: 0.0006875446627170525\n",
      "epoch 119.00 :: 0.0006771707743279297\n",
      "epoch 120.00 :: 0.000667154116937044\n",
      "epoch 121.00 :: 0.0006571914577348666\n",
      "epoch 122.00 :: 0.000647510264322839\n",
      "epoch 123.00 :: 0.0006380563691808758\n",
      "epoch 124.00 :: 0.0006287972977257926\n",
      "epoch 125.00 :: 0.0006197547243738717\n",
      "epoch 126.00 :: 0.000610863681438125\n",
      "epoch 127.00 :: 0.0006021782888141884\n",
      "epoch 128.00 :: 0.0005937094233972443\n",
      "epoch 129.00 :: 0.0005853162649807266\n",
      "epoch 130.00 :: 0.0005771829587915404\n",
      "epoch 131.00 :: 0.0005691578659355979\n",
      "epoch 132.00 :: 0.0005613818119110709\n",
      "epoch 133.00 :: 0.0005536489955953915\n",
      "epoch 134.00 :: 0.000546197713860734\n",
      "epoch 135.00 :: 0.000538789669834924\n",
      "epoch 136.00 :: 0.0005315332012039355\n",
      "epoch 137.00 :: 0.0005244824675504457\n",
      "epoch 138.00 :: 0.0005174533104185354\n",
      "epoch 139.00 :: 0.0005107057143256745\n",
      "epoch 140.00 :: 0.0005039688972332938\n",
      "epoch 141.00 :: 0.0004974270070141012\n",
      "epoch 142.00 :: 0.0004909608317327431\n",
      "epoch 143.00 :: 0.00048466794065792453\n",
      "epoch 144.00 :: 0.0004784183216873895\n",
      "epoch 145.00 :: 0.0004723419604653662\n",
      "epoch 146.00 :: 0.0004663522281175987\n",
      "epoch 147.00 :: 0.0004605032286649062\n",
      "epoch 148.00 :: 0.0004547625444088639\n",
      "epoch 149.00 :: 0.0004490651110906831\n",
      "epoch 150.00 :: 0.000443508482104252\n",
      "epoch 151.00 :: 0.00043806011010681027\n",
      "epoch 152.00 :: 0.0004326767150566659\n",
      "epoch 153.00 :: 0.0004274015902245248\n",
      "epoch 154.00 :: 0.00042224559398495\n",
      "epoch 155.00 :: 0.00041714372822422195\n",
      "epoch 156.00 :: 0.0004121609870873561\n",
      "epoch 157.00 :: 0.000407210702013055\n",
      "epoch 158.00 :: 0.00040241204128092664\n",
      "epoch 159.00 :: 0.0003976133673197844\n",
      "epoch 160.00 :: 0.0003929554738781669\n",
      "epoch 161.00 :: 0.0003883733945919878\n",
      "epoch 162.00 :: 0.0003838237845973874\n",
      "epoch 163.00 :: 0.00037941496967422694\n",
      "epoch 164.00 :: 0.0003750386213968423\n",
      "epoch 165.00 :: 0.00037071641815021974\n",
      "epoch 166.00 :: 0.00036653503246436065\n",
      "epoch 167.00 :: 0.0003623427844352343\n",
      "epoch 168.00 :: 0.0003582155093847012\n",
      "epoch 169.00 :: 0.0003542073708641428\n",
      "epoch 170.00 :: 0.00035023172941609204\n",
      "epoch 171.00 :: 0.00034631022373849356\n",
      "epoch 172.00 :: 0.0003424428630916571\n",
      "epoch 173.00 :: 0.0003386838202872737\n",
      "epoch 174.00 :: 0.00033494643337855285\n",
      "epoch 175.00 :: 0.00033128485401076347\n",
      "epoch 176.00 :: 0.0003276449239241298\n",
      "epoch 177.00 :: 0.00032410247711761093\n",
      "epoch 178.00 :: 0.00032057084635281086\n",
      "epoch 179.00 :: 0.00031715838122181594\n",
      "epoch 180.00 :: 0.000313767556111667\n",
      "epoch 181.00 :: 0.00031045256367757577\n",
      "epoch 182.00 :: 0.00030713754875416106\n",
      "epoch 183.00 :: 0.0003038875240070576\n",
      "epoch 184.00 :: 0.00030063748073933476\n",
      "epoch 185.00 :: 0.00029746326617896557\n",
      "epoch 186.00 :: 0.0002943757056279785\n",
      "epoch 187.00 :: 0.0002913314767118374\n",
      "epoch 188.00 :: 0.0002882872305979783\n",
      "epoch 189.00 :: 0.00028531881583727557\n",
      "epoch 190.00 :: 0.0002823503812330521\n",
      "epoch 191.00 :: 0.0002794902790231969\n",
      "epoch 192.00 :: 0.00027664099814666605\n",
      "epoch 193.00 :: 0.0002738675525919958\n",
      "epoch 194.00 :: 0.00027106158615259284\n",
      "epoch 195.00 :: 0.00026835312283682555\n",
      "epoch 196.00 :: 0.0002656013120113957\n",
      "epoch 197.00 :: 0.0002629144900393757\n",
      "epoch 198.00 :: 0.0002603251791283996\n",
      "epoch 199.00 :: 0.0002576925140932541\n",
      "epoch 200.00 :: 0.0002552115249934352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train_losses, train_accs = [], []\n",
    "    \n",
    "    model.train()\n",
    "    for inp, label in zip(X, y):\n",
    "        inp = torch.Tensor([inp]).long()\n",
    "        label = torch.Tensor(label).long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inp)\n",
    "        label_unsqueeze = torch.unsqueeze(label, 0)\n",
    "        loss = criterion(output[0], torch.max(label_unsqueeze, 1)[1])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "    print(f\"epoch {epoch:.2f} :: {np.average(train_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "c42b40e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:12:12.666699Z",
     "start_time": "2021-12-05T06:12:12.662106Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def sentence_generation(model, tokenizer, current_word, n):\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "    \n",
    "    for _ in range(n):\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "        \n",
    "        result = model(torch.Tensor(encoded).long())\n",
    "        result = torch.max(F.softmax(result[0], dim=1), 1)[1]\n",
    "        \n",
    "        word = list(tokenizer.word_index.keys())[list(tokenizer.word_index.values()).index(result)]\n",
    "        \n",
    "        current_word = current_word + ' ' + word\n",
    "        \n",
    "        sentence = sentence + ' ' + word\n",
    "    \n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "562f4ba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:12:13.335504Z",
     "start_time": "2021-12-05T06:12:13.329807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경마장에 있는 말이 뛰고 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '경마장에', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "4f45c4c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:12:30.649518Z",
     "start_time": "2021-12-05T06:12:30.644885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그의 말이 법이다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '그의', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "8b700d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:12:39.733991Z",
     "start_time": "2021-12-05T06:12:39.727457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가는 말이 고와야 오는 말이 곱다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '가는', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "e3cd8b95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:12:46.955106Z",
     "start_time": "2021-12-05T06:12:46.948846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕 말이 말이 뛰고 있다 고와야\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '안녕', 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8315f433",
   "metadata": {},
   "source": [
    "## LSTM 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe73b5b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "d555adb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:18:17.988413Z",
     "start_time": "2021-12-05T06:18:17.985472Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "d4370195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T06:18:18.225927Z",
     "start_time": "2021-12-05T06:18:18.202149Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  articleWordCount          byline documentType  \\\n",
       "0  5adf6684068401528a2aa69b               781  By JOHN BRANCH      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
       "\n",
       "                                            keywords  multimedia newDesk  \\\n",
       "0  ['Workplace Hazards and Violations', 'Football...          68  Sports   \n",
       "\n",
       "   printPage              pubDate   sectionName  \\\n",
       "0          0  2018-04-24 17:16:49  Pro Football   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  “I understand that they could meet with us, pa...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/timber/Personal/Study/NLP_study_tf/ArticlesApril2018.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "9d4a38d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T07:10:30.833431Z",
     "start_time": "2021-12-05T07:10:30.829270Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
       " 'Is School a Place for Self-Expression?']"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = list(df.headline.values)\n",
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "de6b0413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T07:10:31.129120Z",
     "start_time": "2021-12-05T07:10:31.123735Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1214\n",
      "1214\n",
      "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell', 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.', 'The New Noma, Explained', 'How a Bag of Texas Dirt  Became a Times Tradition', 'Is School a Place for Self-Expression?']\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df[df.headline != 'Unknown']\n",
    "print(len(df))\n",
    "\n",
    "headline = list(df.headline.values)\n",
    "print(headline[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "6e774b69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T07:10:31.344692Z",
     "start_time": "2021-12-05T07:10:31.334637Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
       " 'epa to unveil a new rule its effect less science in policymaking',\n",
       " 'the new noma explained',\n",
       " 'how a bag of texas dirt  became a times tradition',\n",
       " 'is school a place for selfexpression']"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repreprocessing(raw_sentence):\n",
    "    # 구두점 제거\n",
    "    preprocessed_sentence = raw_sentence.encode('utf8').decode('ascii', 'ignore')\n",
    "    return ''.join(word for word in preprocessed_sentence if word not in punctuation).lower()\n",
    "\n",
    "preprocessed_headline = [repreprocessing(x) for x in headline]\n",
    "preprocessed_headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "7123ef78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T07:10:31.560282Z",
     "start_time": "2021-12-05T07:10:31.540731Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합 크기 : 3494\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_headline)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f'단어 집합 크기 : {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "34ff543e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T07:10:31.771404Z",
     "start_time": "2021-12-05T07:10:31.749731Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 269],\n",
       " [99, 269, 371],\n",
       " [99, 269, 371, 1115],\n",
       " [99, 269, 371, 1115, 582],\n",
       " [99, 269, 371, 1115, 582, 52],\n",
       " [99, 269, 371, 1115, 582, 52, 7],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
       " [100, 3]]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = []\n",
    "\n",
    "for sentence in preprocessed_headline:\n",
    "\n",
    "    encoded = tokenizer.texts_to_sequences([sentence])[0] \n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "sequences[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "1785d58f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T07:31:16.431223Z",
     "start_time": "2021-12-05T07:31:16.428086Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "index_to_word={}\n",
    "for k, v in tokenizer.word_index.items():\n",
    "    index_to_word[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "8cea061d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T07:10:33.522765Z",
     "start_time": "2021-12-05T07:10:33.501383Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_len = max(len(l) for l in sequences)\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "0681d53f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T07:31:08.496291Z",
     "start_time": "2021-12-05T07:31:08.485395Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "d3ef34cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T07:31:52.431004Z",
     "start_time": "2021-12-05T07:31:52.414844Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73581425",
   "metadata": {},
   "source": [
    "### 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "c1a4a75e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T07:35:48.869329Z",
     "start_time": "2021-12-05T07:35:48.864842Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class text_LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(text_LSTM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        output = self.embedding(inp)\n",
    "        _, (output, __) = self.lstm(output)\n",
    "        output = self.linear(output)\n",
    "#         output = self.softmax(output) \n",
    "# nn.CrossEntropyLoss에 이미 softmax 함수가 포함된거라서, 따로 해줄 필요는 없다\n",
    "         \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "eae9cc93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T09:34:40.568939Z",
     "start_time": "2021-12-05T07:35:49.825102Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1.00 :: 7.900943478086003\n",
      "epoch 2.00 :: 6.728090529955612\n",
      "epoch 3.00 :: 5.9013966943877225\n",
      "epoch 4.00 :: 5.369305703029424\n",
      "epoch 5.00 :: 5.020713646777665\n",
      "epoch 6.00 :: 4.947484123967058\n",
      "epoch 7.00 :: 4.8535552366062475\n",
      "epoch 8.00 :: 4.748293452578934\n",
      "epoch 9.00 :: 4.4281173842290364\n",
      "epoch 10.00 :: 4.448720963308489\n",
      "epoch 11.00 :: 4.108683002673569\n",
      "epoch 12.00 :: 3.7010637753829645\n",
      "epoch 13.00 :: 3.5861170948561822\n",
      "epoch 14.00 :: 3.162512032427388\n",
      "epoch 15.00 :: 2.9025705229767538\n",
      "epoch 16.00 :: 2.7799290716031337\n",
      "epoch 17.00 :: 2.498691011906624\n",
      "epoch 18.00 :: 2.3217985779156445\n",
      "epoch 19.00 :: 2.032820949528696\n",
      "epoch 20.00 :: 1.8084147286388212\n",
      "epoch 21.00 :: 1.8248933880376945\n",
      "epoch 22.00 :: 1.6327982138771313\n",
      "epoch 23.00 :: 1.473187281201269\n",
      "epoch 24.00 :: 1.3461783292940726\n",
      "epoch 25.00 :: 1.1519929370820345\n",
      "epoch 26.00 :: 1.0416108766569303\n",
      "epoch 27.00 :: 0.8889863503865574\n",
      "epoch 28.00 :: 0.9498417435629661\n",
      "epoch 29.00 :: 0.8037361822755393\n",
      "epoch 30.00 :: 0.7736399621444847\n",
      "epoch 31.00 :: 0.6589851734895391\n",
      "epoch 32.00 :: 0.6501032078414293\n",
      "epoch 33.00 :: 0.6734024978434141\n",
      "epoch 34.00 :: 0.522575572648246\n",
      "epoch 35.00 :: 0.4716639571990609\n",
      "epoch 36.00 :: 0.45621295380910953\n",
      "epoch 37.00 :: 0.3929015219902173\n",
      "epoch 38.00 :: 0.5516392555937255\n",
      "epoch 39.00 :: 0.4147604183857178\n",
      "epoch 40.00 :: 0.6311558571754813\n",
      "epoch 41.00 :: 0.6773955937819669\n",
      "epoch 42.00 :: 0.7908299745534021\n",
      "epoch 43.00 :: 0.52045704079582\n",
      "epoch 44.00 :: 0.7200401452176763\n",
      "epoch 45.00 :: 0.5321411394526883\n",
      "epoch 46.00 :: 0.5835894910837613\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ph/pv7rmwrx0yl4zl9pm78d51hm0000gn/T/ipykernel_34727/2024447760.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_unsqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/NLP_tf/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/NLP_tf/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "embedding_dim = 10\n",
    "hidden_dim = 128\n",
    "lr = 0.001\n",
    "\n",
    "model = text_LSTM(vocab_size=vocab_size,\n",
    "                  embedding_dim=embedding_dim,\n",
    "                  hidden_dim=hidden_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train_losses, train_accs = [], []\n",
    "    \n",
    "    model.train()\n",
    "    for inp, label in zip(X, y):\n",
    "        inp = torch.Tensor([inp]).long()\n",
    "        label = torch.Tensor(label).long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inp)\n",
    "        label_unsqueeze = torch.unsqueeze(label, 0)\n",
    "        loss = criterion(output[0], torch.max(label_unsqueeze, 1)[1])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "    print(f\"epoch {epoch:.2f} :: {np.average(train_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "427b63dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T09:34:42.858658Z",
     "start_time": "2021-12-05T09:34:42.853694Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def sentence_generation(model, tokenizer, current_word, n):\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "    \n",
    "    for _ in range(n):\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "        \n",
    "        result = model(torch.Tensor(encoded).long())\n",
    "        result = torch.max(F.softmax(result[0], dim=1), 1)[1]\n",
    "        \n",
    "        word = list(tokenizer.word_index.keys())[list(tokenizer.word_index.values()).index(result)]\n",
    "        \n",
    "        current_word = current_word + ' ' + word\n",
    "        \n",
    "        sentence = sentence + ' ' + word\n",
    "    \n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "53c726dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T09:34:58.435752Z",
     "start_time": "2021-12-05T09:34:58.374259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i disapprove of school vouchers can i still apply for them\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, 'i', 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73fe09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:NLP_tf] *",
   "language": "python",
   "name": "conda-env-NLP_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
