{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 영어 word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:26:18.727566Z",
     "start_time": "2021-12-09T14:26:18.629711Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "from lxml import etree\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:27:33.921245Z",
     "start_time": "2021-12-09T14:27:11.990500Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x7fd92d70e6a0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:29:03.515686Z",
     "start_time": "2021-12-09T14:28:28.330530Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
    "target_text = etree.parse(targetXML)\n",
    "\n",
    "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "\n",
    "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
    "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "\n",
    "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n",
    "sent_text = sent_tokenize(content_text)\n",
    "\n",
    "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "    normalized_text.append(tokens)\n",
    "\n",
    "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:30:01.351411Z",
     "start_time": "2021-12-09T14:30:01.348572Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 273424\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 개수 : {}'.format(len(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:30:57.205818Z",
     "start_time": "2021-12-09T14:30:57.198286Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
      "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
     ]
    }
   ],
   "source": [
    "for line in result[:3]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:31:53.616907Z",
     "start_time": "2021-12-09T14:31:53.614509Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:33:01.395969Z",
     "start_time": "2021-12-09T14:32:51.957107Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8334362506866455), ('guy', 0.8185007572174072), ('lady', 0.7767740488052368), ('boy', 0.7581679224967957), ('girl', 0.7372376918792725), ('gentleman', 0.730574905872345), ('kid', 0.7141732573509216), ('soldier', 0.6821604371070862), ('photographer', 0.6707069277763367), ('poet', 0.6615515351295471)]\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)\n",
    "\n",
    "model_result = model.wv.most_similar('man')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 한국어 word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T13:19:07.387518Z",
     "start_time": "2021-12-06T13:19:07.368858Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T13:14:09.689393Z",
     "start_time": "2021-12-06T13:14:04.683882Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings.txt', <http.client.HTTPMessage at 0x7ff982a095b0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T13:14:14.051316Z",
     "start_time": "2021-12-06T13:14:13.639707Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_table('ratings.txt')\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T13:15:11.140548Z",
     "start_time": "2021-12-06T13:15:11.109653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_data.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T13:15:49.303771Z",
     "start_time": "2021-12-06T13:15:49.301083Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T13:17:54.098959Z",
     "start_time": "2021-12-06T13:17:51.310274Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['어리다', '때', '보고', '지금', '다시', '보다', '재밌다', 'ㅋㅋ']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt = Okt()\n",
    "sentence = train_data['document'].values[0]\n",
    "okt.morphs(sentence, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T13:31:05.461436Z",
     "start_time": "2021-12-06T13:19:09.179169Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 199992/199992 [11:56<00:00, 279.23it/s]\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "\n",
    "tokenized_data = []\n",
    "for sentence in tqdm(train_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True)\n",
    "    stopwords_removed_sentence = [w for w in tokenized_sentence if w not in stopwords]\n",
    "    tokenized_data.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T14:03:23.702254Z",
     "start_time": "2021-12-06T14:03:22.911793Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 95\n",
      "리뷰의 평균 길이 : 12.338453538141525\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 :',max(len(l) for l in tokenized_data))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, tokenized_data))/len(tokenized_data))\n",
    "plt.hist([len(s) for s in tokenized_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T14:04:54.478195Z",
     "start_time": "2021-12-06T14:04:41.826713Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences = tokenized_data, vector_size=100, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T14:05:48.361843Z",
     "start_time": "2021-12-06T14:05:48.357925Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('한석규', 0.8427351713180542), ('김명민', 0.8418174982070923), ('문소리', 0.8288613557815552), ('서영희', 0.814567506313324), ('안성기', 0.8112744688987732), ('이정재', 0.8036726713180542), ('박해일', 0.8015318512916565), ('유다인', 0.7929420471191406), ('채시라', 0.7925094962120056), ('김창완', 0.7911495566368103)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"최민식\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGNS(Skip-Gram with Neagtive Sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:14:10.014632Z",
     "start_time": "2021-12-13T13:14:08.720890Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:14:11.101577Z",
     "start_time": "2021-12-13T13:14:10.026341Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:14:12.592135Z",
     "start_time": "2021-12-13T13:14:11.532008Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ph/pv7rmwrx0yl4zl9pm78d51hm0000gn/T/ipykernel_54685/3836568661.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10995"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "news_df = pd.DataFrame({'document': documents})\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())\n",
    "\n",
    "news_df.replace(\"\", float(\"NaN\"), inplace=True)\n",
    "news_df.dropna(inplace=True)\n",
    "\n",
    "len(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:14:15.473655Z",
     "start_time": "2021-12-13T13:14:12.998482Z"
    }
   },
   "outputs": [],
   "source": [
    "# 불용어를 제거\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "tokenized_doc = tokenized_doc.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:14:16.039249Z",
     "start_time": "2021-12-13T13:14:16.026814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 : 10940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timber/opt/anaconda3/envs/NLP_tf/lib/python3.8/site-packages/numpy/lib/function_base.py:4454: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "# 단어가 1개 이하인 샘플의 인덱스를 찾아서 저장하고, 해당 샘플들은 제거.\n",
    "drop_train = [index for index, sentence in enumerate(tokenized_doc) if len(sentence) <= 1]\n",
    "tokenized_doc = np.delete(tokenized_doc, drop_train, axis=0)\n",
    "print('총 샘플 수 :',len(tokenized_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:14:17.511710Z",
     "start_time": "2021-12-13T13:14:16.457915Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokenized_doc)\n",
    "\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {value : key for key, value in word2idx.items()}\n",
    "encoded = tokenizer.texts_to_sequences(tokenized_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:14:18.130110Z",
     "start_time": "2021-12-13T13:14:18.127466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 64277\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2idx) + 1 \n",
    "print('단어 집합의 크기 :', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-13T13:14:13.099Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "# 네거티브 샘플링\n",
    "t = time()\n",
    "skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=10) for sample in encoded]\n",
    "print(f'total time : {time()-t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-13T13:14:13.627Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
    "for i in range(5):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "          idx2word[pairs[i][0]], pairs[i][0], \n",
    "          idx2word[pairs[i][1]], pairs[i][1], \n",
    "          labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-13T13:14:15.303Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Reshape, Activation, Input\n",
    "from tensorflow.keras.layers import Dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-13T13:14:15.627Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "sys.path.append('/Users/timber/Personal/Study/NLP_study_tf')\n",
    "from models.sgns import SGNS\n",
    "\n",
    "\n",
    "embedding_dim = 100\n",
    "lr = 0.01\n",
    "model = SGNS(vocab_size=vocab_size, embedding_dim=embedding_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train_losses, train_accs = [], []\n",
    "    \n",
    "    model.train()\n",
    "    for inp, label in zip(X, y):\n",
    "        inp = torch.Tensor([inp]).long()\n",
    "        label = torch.Tensor(label).long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inp)\n",
    "        label_unsqueeze = torch.unsqueeze(label, 0)\n",
    "        loss = criterion(output[0], torch.max(label_unsqueeze, 1)[1])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "    print(f\"epoch {epoch:.2f} :: {np.average(train_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T12:29:25.716506Z",
     "start_time": "2021-12-09T12:29:25.713011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGNS(\n",
       "  (embedding): Embedding(64277, 100)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T12:36:44.146665Z",
     "start_time": "2021-12-09T12:36:44.144600Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/Users/timber/Personal/Study/NLP_study_tf/models/sgns_model'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 글로브 (GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:08:21.715310Z",
     "start_time": "2021-12-09T14:08:20.453749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement glove_python_binary (from versions: none)\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for glove_python_binary\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install glove_python_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glove-python-binary가 더이상 지원 안하나..?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 패스트텍스트(FastText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "맨 위 Word2Vec을 먼저 실행하고 실행해야 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:33:57.603889Z",
     "start_time": "2021-12-09T14:33:57.532160Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'electrofishing' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ph/pv7rmwrx0yl4zl9pm78d51hm0000gn/T/ipykernel_27629/1045970389.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"electrofishing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/NLP_tf/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0mall_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/NLP_tf/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/NLP_tf/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'electrofishing' not present\""
     ]
    }
   ],
   "source": [
    "model.wv.most_similar(\"electrofishing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:38:24.106590Z",
     "start_time": "2021-12-09T14:37:33.669029Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "model = FastText(result, vector_size=100, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T14:39:26.731512Z",
     "start_time": "2021-12-09T14:39:26.704449Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('electrolyte', 0.8709851503372192),\n",
       " ('electrolux', 0.8707529306411743),\n",
       " ('electro', 0.8637531399726868),\n",
       " ('electroshock', 0.8580990433692932),\n",
       " ('electrochemical', 0.8394168615341187),\n",
       " ('electric', 0.8341692686080933),\n",
       " ('electroencephalogram', 0.8331431746482849),\n",
       " ('electrogram', 0.8274303674697876),\n",
       " ('airbus', 0.8229468464851379),\n",
       " ('electron', 0.8227265477180481)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"electrofishing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:14:43.018539Z",
     "start_time": "2021-12-13T13:14:38.748911Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:14:49.306322Z",
     "start_time": "2021-12-13T13:14:49.303802Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
    "y_train = [1, 0, 0, 1, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:14:49.532394Z",
     "start_time": "2021-12-13T13:14:49.529418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:14:49.985021Z",
     "start_time": "2021-12-13T13:14:49.982482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
     ]
    }
   ],
   "source": [
    "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
    "print(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:28:38.744360Z",
     "start_time": "2021-12-13T13:28:38.740293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  0  0]\n",
      " [ 7  8  0  0]\n",
      " [ 9 10  0  0]\n",
      " [11 12  0  0]\n",
      " [13  0  0  0]\n",
      " [14 15  0  0]]\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in X_encoded)\n",
    "\n",
    "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
    "y_train = np.array(y_train)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:15:14.588147Z",
     "start_time": "2021-12-13T13:15:14.584938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  0,  0],\n",
       "       [ 7,  8,  0,  0],\n",
       "       [ 9, 10,  0,  0],\n",
       "       [11, 12,  0,  0],\n",
       "       [13,  0,  0,  0],\n",
       "       [14, 15,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T13:35:27.928583Z",
     "start_time": "2021-12-13T13:35:27.121584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1.00 :: 0.9880989279065814\n",
      "epoch 2.00 :: 0.8543796965054103\n",
      "epoch 3.00 :: 0.7737449833324977\n",
      "epoch 4.00 :: 0.7118992635181972\n",
      "epoch 5.00 :: 0.6624553714479718\n",
      "epoch 6.00 :: 0.6214179907526288\n",
      "epoch 7.00 :: 0.5855755167348045\n",
      "epoch 8.00 :: 0.5523378465856824\n",
      "epoch 9.00 :: 0.5198567977973393\n",
      "epoch 10.00 :: 0.48704048565455843\n",
      "epoch 11.00 :: 0.4534243089812143\n",
      "epoch 12.00 :: 0.41900969190256937\n",
      "epoch 13.00 :: 0.3841209411621094\n",
      "epoch 14.00 :: 0.34928392086710247\n",
      "epoch 15.00 :: 0.3151185427393232\n",
      "epoch 16.00 :: 0.28224595742566244\n",
      "epoch 17.00 :: 0.2512142817888941\n",
      "epoch 18.00 :: 0.2224483617714473\n",
      "epoch 19.00 :: 0.19622544199228287\n",
      "epoch 20.00 :: 0.17267438769340515\n",
      "epoch 21.00 :: 0.15179237936224257\n",
      "epoch 22.00 :: 0.13347151981932776\n",
      "epoch 23.00 :: 0.11752986535429955\n",
      "epoch 24.00 :: 0.10374107477920395\n",
      "epoch 25.00 :: 0.09185993352106639\n",
      "epoch 26.00 :: 0.08164194093218871\n",
      "epoch 27.00 :: 0.07285604013928346\n",
      "epoch 28.00 :: 0.06529285625687667\n",
      "epoch 29.00 :: 0.05876761382179601\n",
      "epoch 30.00 :: 0.05312088557652065\n",
      "epoch 31.00 :: 0.0482167082705668\n",
      "epoch 32.00 :: 0.043940596016389985\n",
      "epoch 33.00 :: 0.040196578949689865\n",
      "epoch 34.00 :: 0.036904542174722464\n",
      "epoch 35.00 :: 0.03399768019361155\n",
      "epoch 36.00 :: 0.03142018350107329\n",
      "epoch 37.00 :: 0.02912547891693456\n",
      "epoch 38.00 :: 0.02707456225263221\n",
      "epoch 39.00 :: 0.025234722266239778\n",
      "epoch 40.00 :: 0.02357825357466936\n",
      "epoch 41.00 :: 0.022081817566816295\n",
      "epoch 42.00 :: 0.020725630090704987\n",
      "epoch 43.00 :: 0.019492653930293664\n",
      "epoch 44.00 :: 0.01836852782538959\n",
      "epoch 45.00 :: 0.01734074531123042\n",
      "epoch 46.00 :: 0.016398572496005466\n",
      "epoch 47.00 :: 0.015532755359475101\n",
      "epoch 48.00 :: 0.014735189333025898\n",
      "epoch 49.00 :: 0.013998852710106544\n",
      "epoch 50.00 :: 0.013317598695201533\n",
      "epoch 51.00 :: 0.012686032602297408\n",
      "epoch 52.00 :: 0.012099383864551783\n",
      "epoch 53.00 :: 0.011553411505052022\n",
      "epoch 54.00 :: 0.01104444355171706\n",
      "epoch 55.00 :: 0.010569177235343627\n",
      "epoch 56.00 :: 0.010124667747212308\n",
      "epoch 57.00 :: 0.009708227356895804\n",
      "epoch 58.00 :: 0.009317613805511169\n",
      "epoch 59.00 :: 0.008950592850201897\n",
      "epoch 60.00 :: 0.0086053975392133\n",
      "epoch 61.00 :: 0.00828023740489568\n",
      "epoch 62.00 :: 0.007973552881074803\n",
      "epoch 63.00 :: 0.007684033696672746\n",
      "epoch 64.00 :: 0.007410282634996942\n",
      "epoch 65.00 :: 0.007151270251987236\n",
      "epoch 66.00 :: 0.006905897054821253\n",
      "epoch 67.00 :: 0.006673196496974144\n",
      "epoch 68.00 :: 0.0064523189794272184\n",
      "epoch 69.00 :: 0.00624242947170777\n",
      "epoch 70.00 :: 0.006042861013806292\n",
      "epoch 71.00 :: 0.005852928617969155\n",
      "epoch 72.00 :: 0.005671945866197348\n",
      "epoch 73.00 :: 0.00549941197303789\n",
      "epoch 74.00 :: 0.0053347571353827205\n",
      "epoch 75.00 :: 0.005177563355703439\n",
      "epoch 76.00 :: 0.005027327553502151\n",
      "epoch 77.00 :: 0.004883647630257266\n",
      "epoch 78.00 :: 0.004746137735699969\n",
      "epoch 79.00 :: 0.004614496370777488\n",
      "epoch 80.00 :: 0.00448831995683057\n",
      "epoch 81.00 :: 0.004367306362837553\n",
      "epoch 82.00 :: 0.00425123780899282\n",
      "epoch 83.00 :: 0.0041398284291582444\n",
      "epoch 84.00 :: 0.004032758197614125\n",
      "epoch 85.00 :: 0.0039298766392416185\n",
      "epoch 86.00 :: 0.0038309137536478893\n",
      "epoch 87.00 :: 0.003735718782991171\n",
      "epoch 88.00 :: 0.003644072517220463\n",
      "epoch 89.00 :: 0.0035557899224971023\n",
      "epoch 90.00 :: 0.0034707363062937346\n",
      "epoch 91.00 :: 0.003388692342144038\n",
      "epoch 92.00 :: 0.003309607954828867\n",
      "epoch 93.00 :: 0.003233280698103564\n",
      "epoch 94.00 :: 0.00315957549693329\n",
      "epoch 95.00 :: 0.00308837418976639\n",
      "epoch 96.00 :: 0.003019575944303402\n",
      "epoch 97.00 :: 0.0029530964592205627\n",
      "epoch 98.00 :: 0.0028888004765446696\n",
      "epoch 99.00 :: 0.002826603761475001\n",
      "epoch 100.00 :: 0.00276638800278306\n",
      "epoch 101.00 :: 0.0027081366029701064\n",
      "epoch 102.00 :: 0.002651663330782737\n",
      "epoch 103.00 :: 0.002596985432319343\n",
      "epoch 104.00 :: 0.0025439677078143825\n",
      "epoch 105.00 :: 0.0024925762471476836\n",
      "epoch 106.00 :: 0.0024427096941508353\n",
      "epoch 107.00 :: 0.002394351318279015\n",
      "epoch 108.00 :: 0.00234743334918416\n",
      "epoch 109.00 :: 0.0023018542727056357\n",
      "epoch 110.00 :: 0.0022576312850495534\n",
      "epoch 111.00 :: 0.002214662647540016\n",
      "epoch 112.00 :: 0.0021728807062442812\n",
      "epoch 113.00 :: 0.002132302540953138\n",
      "epoch 114.00 :: 0.002092843484466097\n",
      "epoch 115.00 :: 0.002054469668239887\n",
      "epoch 116.00 :: 0.002017147306885038\n",
      "epoch 117.00 :: 0.001980825560167432\n",
      "epoch 118.00 :: 0.0019454706177514578\n",
      "epoch 119.00 :: 0.0019110655661539308\n",
      "epoch 120.00 :: 0.0018775426100806466\n",
      "epoch 121.00 :: 0.0018449188542685338\n",
      "epoch 122.00 :: 0.0018131094070018402\n",
      "epoch 123.00 :: 0.0017821313813328743\n",
      "epoch 124.00 :: 0.0017518998689151236\n",
      "epoch 125.00 :: 0.00172246597607487\n",
      "epoch 126.00 :: 0.0016937278061439948\n",
      "epoch 127.00 :: 0.0016657364155564988\n",
      "epoch 128.00 :: 0.0016384409723936447\n",
      "epoch 129.00 :: 0.0016117734485305846\n",
      "epoch 130.00 :: 0.0015857168805918523\n",
      "epoch 131.00 :: 0.0015603224830036716\n",
      "epoch 132.00 :: 0.0015355392242781818\n",
      "epoch 133.00 :: 0.0015113161477659429\n",
      "epoch 134.00 :: 0.0014876533283053764\n",
      "epoch 135.00 :: 0.001464550832419523\n",
      "epoch 136.00 :: 0.0014419747167266905\n",
      "epoch 137.00 :: 0.0014198909297452442\n",
      "epoch 138.00 :: 0.0013983166011582529\n",
      "epoch 139.00 :: 0.0013772177626378834\n",
      "epoch 140.00 :: 0.0013566114607134036\n",
      "epoch 141.00 :: 0.0013364296755753458\n",
      "epoch 142.00 :: 0.0013167064587053443\n",
      "epoch 143.00 :: 0.00129739087008472\n",
      "epoch 144.00 :: 0.0012784999063504593\n",
      "epoch 145.00 :: 0.0012600506306625903\n",
      "epoch 146.00 :: 0.0012419409717300109\n",
      "epoch 147.00 :: 0.001224222085771284\n",
      "epoch 148.00 :: 0.0012068769137840718\n",
      "epoch 149.00 :: 0.0011898714874405414\n",
      "epoch 150.00 :: 0.0011732738764424408\n",
      "epoch 151.00 :: 0.0011569479829631746\n",
      "epoch 152.00 :: 0.0011410129289808018\n",
      "epoch 153.00 :: 0.0011253496798287546\n",
      "epoch 154.00 :: 0.001110043251953487\n",
      "epoch 155.00 :: 0.0010950086954315858\n",
      "epoch 156.00 :: 0.0010802970168047718\n",
      "epoch 157.00 :: 0.0010658572095313243\n",
      "epoch 158.00 :: 0.001051672239555046\n",
      "epoch 159.00 :: 0.001037810226469966\n",
      "epoch 160.00 :: 0.0010241520441403346\n",
      "epoch 161.00 :: 0.0010108338361273386\n",
      "epoch 162.00 :: 0.0009977025370712259\n",
      "epoch 163.00 :: 0.0009848431842069008\n",
      "epoch 164.00 :: 0.0009722217551565596\n",
      "epoch 165.00 :: 0.00095985531723792\n",
      "epoch 166.00 :: 0.0009476757799607835\n",
      "epoch 167.00 :: 0.0009357682553984757\n",
      "epoch 168.00 :: 0.0009240476813699518\n",
      "epoch 169.00 :: 0.0009125480802530157\n",
      "epoch 170.00 :: 0.0009012524595683706\n",
      "epoch 171.00 :: 0.0008901608234737068\n",
      "epoch 172.00 :: 0.0008792731636536441\n",
      "epoch 173.00 :: 0.0008685725250480962\n",
      "epoch 174.00 :: 0.0008580418486547257\n",
      "epoch 175.00 :: 0.0008477322407998145\n",
      "epoch 176.00 :: 0.0008375585810946566\n",
      "epoch 177.00 :: 0.0008275889517140708\n",
      "epoch 178.00 :: 0.0008177893178071827\n",
      "epoch 179.00 :: 0.0008081597417393434\n",
      "epoch 180.00 :: 0.000798683164508215\n",
      "epoch 181.00 :: 0.0007893425686883607\n",
      "epoch 182.00 :: 0.0007801720099191048\n",
      "epoch 183.00 :: 0.000771188534729715\n",
      "epoch 184.00 :: 0.0007623410534246691\n",
      "epoch 185.00 :: 0.0007536296034231782\n",
      "epoch 186.00 :: 0.0007450541764098619\n",
      "epoch 187.00 :: 0.0007366147807001003\n",
      "epoch 188.00 :: 0.0007283624560971345\n",
      "epoch 189.00 :: 0.0007201781554613262\n",
      "epoch 190.00 :: 0.000712146857819919\n",
      "epoch 191.00 :: 0.0007042516496897276\n",
      "epoch 192.00 :: 0.0006964924603900206\n",
      "epoch 193.00 :: 0.000688852318229952\n",
      "epoch 194.00 :: 0.0006812971883586475\n",
      "epoch 195.00 :: 0.0006738951446355454\n",
      "epoch 196.00 :: 0.0006665951181535742\n",
      "epoch 197.00 :: 0.0006594311687097486\n",
      "epoch 198.00 :: 0.0006523522440277572\n",
      "epoch 199.00 :: 0.000645375344902277\n",
      "epoch 200.00 :: 0.0006385005045948284\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 4\n",
    "\n",
    "class EMB(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                      embedding_dim=embedding_dim)\n",
    "        self.linear = nn.Linear(16, 1)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        output = self.embedding(inp)\n",
    "        output = nn.Flatten()(output)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "    \n",
    "model = EMB(vocab_size, embedding_dim)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train_losses, train_accs = [], []\n",
    "    \n",
    "    model.train()\n",
    "    for inp, label in zip(X_train, y_train):\n",
    "        inp = torch.Tensor([inp]).long()\n",
    "        label = torch.Tensor([label]).float()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inp)\n",
    "        loss = criterion(output[0], label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "    print(f\"epoch {epoch:.2f} :: {np.average(train_losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전훈련 GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T14:01:41.015273Z",
     "start_time": "2021-12-13T13:42:20.553701Z"
    }
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve, urlopen\n",
    "import gzip\n",
    "import zipfile\n",
    "\n",
    "urlretrieve(\"http://nlp.stanford.edu/data/glove.6B.zip\", filename=\"glove.6B.zip\")\n",
    "zf = zipfile.ZipFile('glove.6B.zip')\n",
    "zf.extractall() \n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T14:02:51.112415Z",
     "start_time": "2021-12-13T14:02:43.850755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000개의 Embedding vector가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "embedding_dict = dict()\n",
    "\n",
    "f = open('dataset/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "    word_vector = line.split()\n",
    "    word = word_vector[0]\n",
    "\n",
    "    # 100개의 값을 가지는 array로 변환\n",
    "    word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n",
    "    embedding_dict[word] = word_vector_arr\n",
    "f.close()\n",
    "\n",
    "print(f'{len(embedding_dict)}개의 Embedding vector가 있습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T14:05:25.247419Z",
     "start_time": "2021-12-13T14:05:25.247399Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "np.shape(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T14:05:25.257569Z",
     "start_time": "2021-12-13T14:05:25.257486Z"
    }
   },
   "outputs": [],
   "source": [
    "for word, index in tokenizer.word_index.items():\n",
    "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
    "    vector_value = embedding_dict.get(word)\n",
    "    if vector_value is not None:\n",
    "        embedding_matrix[index] = vector_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T14:05:25.266688Z",
     "start_time": "2021-12-13T14:05:25.266670Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 4\n",
    "\n",
    "class EMB_GLOVE(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, embedding_matrix):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                      embedding_dim=embedding_dim,\n",
    "                                      padding_idx=embedding_matrix)\n",
    "        self.linear = nn.Linear(16, 1)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        output = self.embedding(inp)\n",
    "        output = nn.Flatten()(output)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "    \n",
    "model = EMB_GLOVE(vocab_size, embedding_dim, embedding_matrix)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train_losses, train_accs = [], []\n",
    "    \n",
    "    model.train()\n",
    "    for inp, label in zip(X_train, y_train):\n",
    "        inp = torch.Tensor([inp]).long()\n",
    "        label = torch.Tensor([label]).float()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inp)\n",
    "        loss = criterion(output[0], label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "    print(f\"epoch {epoch:.2f} :: {np.average(train_losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Google 사의 word2vec 모델을 가져오는건 GloVe랑 다를 부분이 없으니 생략"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "NLP_env",
   "language": "python",
   "name": "nlp_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
